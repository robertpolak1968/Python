{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to Prepare Text Data for Machine Learning with scikit-learn\n",
    "#Movie review dataset:“txt_sentoken” with two sub-directories containing the text “neg” and “pos” \n",
    "#for negative and positive reviews.Reviews are stored one per file with a naming convention \n",
    "#cv000 to cv999 for each of neg and pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries \n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1: A function called load_doc() that takes a filename of the document to load and returns the text.\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cv676_22202.txt\n",
      "Loaded cv839_22807.txt\n",
      "Loaded cv155_7845.txt\n",
      "Loaded cv465_23401.txt\n",
      "Loaded cv398_17047.txt\n",
      "Loaded cv206_15893.txt\n",
      "Loaded cv037_19798.txt\n",
      "Loaded cv279_19452.txt\n",
      "Loaded cv646_16817.txt\n",
      "Loaded cv756_23676.txt\n",
      "Loaded cv823_17055.txt\n",
      "Loaded cv747_18189.txt\n",
      "Loaded cv258_5627.txt\n",
      "Loaded cv948_25870.txt\n",
      "Loaded cv744_10091.txt\n",
      "Loaded cv754_7709.txt\n",
      "Loaded cv838_25886.txt\n",
      "Loaded cv131_11568.txt\n",
      "Loaded cv401_13758.txt\n",
      "Loaded cv523_18285.txt\n",
      "Loaded cv073_23039.txt\n",
      "Loaded cv688_7884.txt\n",
      "Loaded cv664_4264.txt\n",
      "Loaded cv461_21124.txt\n",
      "Loaded cv909_9973.txt\n",
      "Loaded cv939_11247.txt\n",
      "Loaded cv368_11090.txt\n",
      "Loaded cv185_28372.txt\n",
      "Loaded cv749_18960.txt\n",
      "Loaded cv836_14311.txt\n",
      "Loaded cv322_21820.txt\n",
      "Loaded cv789_12991.txt\n",
      "Loaded cv617_9561.txt\n",
      "Loaded cv288_20212.txt\n",
      "Loaded cv464_17076.txt\n",
      "Loaded cv904_25663.txt\n",
      "Loaded cv866_29447.txt\n",
      "Loaded cv429_7937.txt\n",
      "Loaded cv212_10054.txt\n",
      "Loaded cv007_4992.txt\n",
      "Loaded cv522_5418.txt\n",
      "Loaded cv109_22599.txt\n",
      "Loaded cv753_11812.txt\n",
      "Loaded cv312_29308.txt\n",
      "Loaded cv294_12695.txt\n",
      "Loaded cv886_19210.txt\n",
      "Loaded cv479_5450.txt\n",
      "Loaded cv867_18362.txt\n",
      "Loaded cv260_15652.txt\n",
      "Loaded cv313_19337.txt\n",
      "Loaded cv317_25111.txt\n",
      "Loaded cv506_17521.txt\n",
      "Loaded cv602_8830.txt\n",
      "Loaded cv710_23745.txt\n",
      "Loaded cv971_11790.txt\n",
      "Loaded cv098_17021.txt\n",
      "Loaded cv960_28877.txt\n",
      "Loaded cv423_12089.txt\n",
      "Loaded cv887_5306.txt\n",
      "Loaded cv291_26844.txt\n",
      "Loaded cv049_21917.txt\n",
      "Loaded cv382_8393.txt\n",
      "Loaded cv915_9342.txt\n",
      "Loaded cv217_28707.txt\n",
      "Loaded cv729_10475.txt\n",
      "Loaded cv862_15924.txt\n",
      "Loaded cv034_29446.txt\n",
      "Loaded cv560_18608.txt\n",
      "Loaded cv684_12727.txt\n",
      "Loaded cv627_12603.txt\n",
      "Loaded cv498_9288.txt\n",
      "Loaded cv044_18429.txt\n",
      "Loaded cv359_6751.txt\n",
      "Loaded cv537_13516.txt\n",
      "Loaded cv089_12222.txt\n",
      "Loaded cv784_16077.txt\n",
      "Loaded cv801_26335.txt\n",
      "Loaded cv692_17026.txt\n",
      "Loaded cv531_26838.txt\n",
      "Loaded cv913_29127.txt\n",
      "Loaded cv319_16459.txt\n",
      "Loaded cv377_8440.txt\n",
      "Loaded cv943_23547.txt\n",
      "Loaded cv691_5090.txt\n",
      "Loaded cv604_23339.txt\n",
      "Loaded cv327_21743.txt\n",
      "Loaded cv718_12227.txt\n",
      "Loaded cv686_15553.txt\n",
      "Loaded cv195_16146.txt\n",
      "Loaded cv170_29808.txt\n",
      "Loaded cv254_5870.txt\n",
      "Loaded cv435_24355.txt\n",
      "Loaded cv184_26935.txt\n",
      "Loaded cv388_12810.txt\n",
      "Loaded cv835_20531.txt\n",
      "Loaded cv541_28683.txt\n",
      "Loaded cv609_25038.txt\n",
      "Loaded cv708_28539.txt\n",
      "Loaded cv386_10229.txt\n",
      "Loaded cv392_12238.txt\n",
      "Loaded cv822_21545.txt\n",
      "Loaded cv758_9740.txt\n",
      "Loaded cv819_9567.txt\n",
      "Loaded cv704_17622.txt\n",
      "Loaded cv458_9000.txt\n",
      "Loaded cv679_28221.txt\n",
      "Loaded cv097_26081.txt\n",
      "Loaded cv740_13643.txt\n",
      "Loaded cv773_20264.txt\n",
      "Loaded cv600_25043.txt\n",
      "Loaded cv416_12048.txt\n",
      "Loaded cv702_12371.txt\n",
      "Loaded cv527_10338.txt\n",
      "Loaded cv055_8926.txt\n",
      "Loaded cv798_24779.txt\n",
      "Loaded cv371_8197.txt\n",
      "Loaded cv549_22771.txt\n",
      "Loaded cv283_11963.txt\n",
      "Loaded cv430_18662.txt\n",
      "Loaded cv921_13988.txt\n",
      "Loaded cv730_10729.txt\n",
      "Loaded cv107_25639.txt\n",
      "Loaded cv705_11973.txt\n",
      "Loaded cv421_9752.txt\n",
      "Loaded cv447_27334.txt\n",
      "Loaded cv739_12179.txt\n",
      "Loaded cv240_15948.txt\n",
      "Loaded cv122_7891.txt\n",
      "Loaded cv460_11723.txt\n",
      "Loaded cv893_26731.txt\n",
      "Loaded cv234_22123.txt\n",
      "Loaded cv803_8584.txt\n",
      "Loaded cv379_23167.txt\n",
      "Loaded cv198_19313.txt\n",
      "Loaded cv556_16563.txt\n",
      "Loaded cv632_9704.txt\n",
      "Loaded cv853_29119.txt\n",
      "Loaded cv023_13847.txt\n",
      "Loaded cv410_25624.txt\n",
      "Loaded cv490_18986.txt\n",
      "Loaded cv755_24881.txt\n",
      "Loaded cv930_14949.txt\n",
      "Loaded cv645_17078.txt\n",
      "Loaded cv497_27086.txt\n",
      "Loaded cv876_9633.txt\n",
      "Loaded cv841_3367.txt\n",
      "Loaded cv318_11146.txt\n",
      "Loaded cv189_24248.txt\n",
      "Loaded cv888_25678.txt\n",
      "Loaded cv210_9557.txt\n",
      "Loaded cv815_23466.txt\n",
      "Loaded cv227_25406.txt\n",
      "Loaded cv748_14044.txt\n",
      "Loaded cv667_19672.txt\n",
      "Loaded cv437_24070.txt\n",
      "Loaded cv988_20168.txt\n",
      "Loaded cv027_26270.txt\n",
      "Loaded cv918_27080.txt\n",
      "Loaded cv768_12709.txt\n",
      "Loaded cv036_18385.txt\n",
      "Loaded cv938_10706.txt\n",
      "Loaded cv362_16985.txt\n",
      "Loaded cv849_17215.txt\n",
      "Loaded cv144_5010.txt\n",
      "Loaded cv320_9693.txt\n",
      "Loaded cv492_19370.txt\n",
      "Loaded cv112_12178.txt\n",
      "Loaded cv558_29376.txt\n",
      "Loaded cv141_17179.txt\n",
      "Loaded cv168_7435.txt\n",
      "Loaded cv944_15042.txt\n",
      "Loaded cv308_5079.txt\n",
      "Loaded cv752_25330.txt\n",
      "Loaded cv356_26170.txt\n",
      "Loaded cv738_10287.txt\n",
      "Loaded cv731_3968.txt\n",
      "Loaded cv519_16239.txt\n",
      "Loaded cv847_20855.txt\n",
      "Loaded cv687_22207.txt\n",
      "Loaded cv854_18955.txt\n",
      "Loaded cv050_12128.txt\n",
      "Loaded cv179_9533.txt\n",
      "Loaded cv489_19046.txt\n",
      "Loaded cv127_16451.txt\n",
      "Loaded cv496_11185.txt\n",
      "Loaded cv614_11320.txt\n",
      "Loaded cv140_7963.txt\n",
      "Loaded cv987_7394.txt\n",
      "Loaded cv851_21895.txt\n",
      "Loaded cv228_5644.txt\n",
      "Loaded cv542_20359.txt\n",
      "Loaded cv225_29083.txt\n",
      "Loaded cv063_28852.txt\n",
      "Loaded cv341_25667.txt\n",
      "Loaded cv563_18610.txt\n",
      "Loaded cv022_14227.txt\n",
      "Loaded cv520_13297.txt\n",
      "Loaded cv102_8306.txt\n",
      "Loaded cv150_14279.txt\n",
      "Loaded cv858_20266.txt\n",
      "Loaded cv936_17473.txt\n",
      "Loaded cv762_15604.txt\n",
      "Loaded cv891_6035.txt\n",
      "Loaded cv445_26683.txt\n",
      "Loaded cv946_20084.txt\n",
      "Loaded cv507_9509.txt\n",
      "Loaded cv330_29675.txt\n",
      "Loaded cv350_22139.txt\n",
      "Loaded cv837_27232.txt\n",
      "Loaded cv347_14722.txt\n",
      "Loaded cv483_18103.txt\n",
      "Loaded cv287_17410.txt\n",
      "Loaded cv777_10247.txt\n",
      "Loaded cv630_10152.txt\n",
      "Loaded cv975_11920.txt\n",
      "Loaded cv633_29730.txt\n",
      "Loaded cv028_26964.txt\n",
      "Loaded cv101_10537.txt\n",
      "Loaded cv171_15164.txt\n",
      "Loaded cv554_14678.txt\n",
      "Loaded cv963_7208.txt\n",
      "Loaded cv775_17966.txt\n",
      "Loaded cv564_12011.txt\n",
      "Loaded cv448_16409.txt\n",
      "Loaded cv681_9744.txt\n",
      "Loaded cv865_28796.txt\n",
      "Loaded cv770_11061.txt\n",
      "Loaded cv264_14108.txt\n",
      "Loaded cv650_15974.txt\n",
      "Loaded cv714_19704.txt\n",
      "Loaded cv607_8235.txt\n",
      "Loaded cv699_7773.txt\n",
      "Loaded cv205_9676.txt\n",
      "Loaded cv297_10104.txt\n",
      "Loaded cv491_12992.txt\n",
      "Loaded cv310_14568.txt\n",
      "Loaded cv475_22978.txt\n",
      "Loaded cv824_9335.txt\n",
      "Loaded cv941_10718.txt\n",
      "Loaded cv965_26688.txt\n",
      "Loaded cv176_14196.txt\n",
      "Loaded cv349_15032.txt\n",
      "Loaded cv612_5396.txt\n",
      "Loaded cv053_23117.txt\n",
      "Loaded cv040_8829.txt\n",
      "Loaded cv370_5338.txt\n",
      "Loaded cv203_19052.txt\n",
      "Loaded cv623_16988.txt\n",
      "Loaded cv937_9816.txt\n",
      "Loaded cv394_5311.txt\n",
      "Loaded cv054_4101.txt\n",
      "Loaded cv139_14236.txt\n",
      "Loaded cv134_23300.txt\n",
      "Loaded cv580_15681.txt\n",
      "Loaded cv986_15092.txt\n",
      "Loaded cv611_2253.txt\n",
      "Loaded cv816_15257.txt\n",
      "Loaded cv393_29234.txt\n",
      "Loaded cv326_14777.txt\n",
      "Loaded cv302_26481.txt\n",
      "Loaded cv010_29063.txt\n",
      "Loaded cv415_23674.txt\n",
      "Loaded cv932_14854.txt\n",
      "Loaded cv003_12683.txt\n",
      "Loaded cv962_9813.txt\n",
      "Loaded cv115_26443.txt\n",
      "Loaded cv409_29625.txt\n",
      "Loaded cv180_17823.txt\n",
      "Loaded cv502_10970.txt\n",
      "Loaded cv615_15734.txt\n",
      "Loaded cv735_20218.txt\n",
      "Loaded cv482_11233.txt\n",
      "Loaded cv324_7502.txt\n",
      "Loaded cv926_18471.txt\n",
      "Loaded cv844_13890.txt\n",
      "Loaded cv845_15886.txt\n",
      "Loaded cv257_11856.txt\n",
      "Loaded cv335_16299.txt\n",
      "Loaded cv634_11989.txt\n",
      "Loaded cv200_29006.txt\n",
      "Loaded cv192_16079.txt\n",
      "Loaded cv759_15091.txt\n",
      "Loaded cv009_29417.txt\n",
      "Loaded cv123_12165.txt\n",
      "Loaded cv024_7033.txt\n",
      "Loaded cv655_12055.txt\n",
      "Loaded cv366_10709.txt\n",
      "Loaded cv208_9475.txt\n",
      "Loaded cv931_18783.txt\n",
      "Loaded cv656_25395.txt\n",
      "Loaded cv828_21392.txt\n",
      "Loaded cv440_16891.txt\n",
      "Loaded cv146_19587.txt\n",
      "Loaded cv671_5164.txt\n",
      "Loaded cv113_24354.txt\n",
      "Loaded cv501_12675.txt\n",
      "Loaded cv493_14135.txt\n",
      "Loaded cv622_8583.txt\n",
      "Loaded cv643_29282.txt\n",
      "Loaded cv703_17948.txt\n",
      "Loaded cv121_18621.txt\n",
      "Loaded cv378_21982.txt\n",
      "Loaded cv902_13217.txt\n",
      "Loaded cv162_10977.txt\n",
      "Loaded cv922_10185.txt\n",
      "Loaded cv105_19135.txt\n",
      "Loaded cv006_17022.txt\n",
      "Loaded cv526_12868.txt\n",
      "Loaded cv390_12187.txt\n",
      "Loaded cv885_13390.txt\n",
      "Loaded cv778_18629.txt\n",
      "Loaded cv535_21183.txt\n",
      "Loaded cv088_25274.txt\n",
      "Loaded cv128_29444.txt\n",
      "Loaded cv525_17930.txt\n",
      "Loaded cv651_11120.txt\n",
      "Loaded cv905_28965.txt\n",
      "Loaded cv592_23391.txt\n",
      "Loaded cv665_29386.txt\n",
      "Loaded cv137_17020.txt\n",
      "Loaded cv534_15683.txt\n",
      "Loaded cv295_17060.txt\n",
      "Loaded cv411_16799.txt\n",
      "Loaded cv499_11407.txt\n",
      "Loaded cv782_21078.txt\n",
      "Loaded cv201_7421.txt\n",
      "Loaded cv883_27621.txt\n",
      "Loaded cv292_7804.txt\n",
      "Loaded cv282_6833.txt\n",
      "Loaded cv065_16909.txt\n",
      "Loaded cv776_21934.txt\n",
      "Loaded cv487_11058.txt\n",
      "Loaded cv969_14760.txt\n",
      "Loaded cv964_5794.txt\n",
      "Loaded cv925_9459.txt\n",
      "Loaded cv979_2029.txt\n",
      "Loaded cv553_26965.txt\n",
      "Loaded cv638_29394.txt\n",
      "Loaded cv795_10291.txt\n",
      "Loaded cv610_24153.txt\n",
      "Loaded cv725_10266.txt\n",
      "Loaded cv035_3343.txt\n",
      "Loaded cv923_11951.txt\n",
      "Loaded cv884_15230.txt\n",
      "Loaded cv352_5414.txt\n",
      "Loaded cv025_29825.txt\n",
      "Loaded cv426_10976.txt\n",
      "Loaded cv223_28923.txt\n",
      "Loaded cv074_7188.txt\n",
      "Loaded cv467_26610.txt\n",
      "Loaded cv114_19501.txt\n",
      "Loaded cv038_9781.txt\n",
      "Loaded cv296_13146.txt\n",
      "Loaded cv514_12173.txt\n",
      "Loaded cv790_16202.txt\n",
      "Loaded cv015_29356.txt\n",
      "Loaded cv547_18043.txt\n",
      "Loaded cv270_5873.txt\n",
      "Loaded cv529_10972.txt\n",
      "Loaded cv485_26879.txt\n",
      "Loaded cv736_24947.txt\n",
      "Loaded cv271_15364.txt\n",
      "Loaded cv289_6239.txt\n",
      "Loaded cv344_5376.txt\n",
      "Loaded cv745_14009.txt\n",
      "Loaded cv165_2389.txt\n",
      "Loaded cv585_23576.txt\n",
      "Loaded cv384_18536.txt\n",
      "Loaded cv763_16486.txt\n",
      "Loaded cv442_15499.txt\n",
      "Loaded cv033_25680.txt\n",
      "Loaded cv933_24953.txt\n",
      "Loaded cv641_13412.txt\n",
      "Loaded cv216_20165.txt\n",
      "Loaded cv601_24759.txt\n",
      "Loaded cv572_20053.txt\n",
      "Loaded cv894_22140.txt\n",
      "Loaded cv618_9469.txt\n",
      "Loaded cv376_20883.txt\n",
      "Loaded cv860_15520.txt\n",
      "Loaded cv914_2856.txt\n",
      "Loaded cv983_24219.txt\n",
      "Loaded cv583_29465.txt\n",
      "Loaded cv584_29549.txt\n",
      "Loaded cv166_11959.txt\n",
      "Loaded cv959_16218.txt\n",
      "Loaded cv004_12641.txt\n",
      "Loaded cv706_25883.txt\n",
      "Loaded cv579_12542.txt\n",
      "Loaded cv947_11316.txt\n",
      "Loaded cv929_1841.txt\n",
      "Loaded cv713_29002.txt\n",
      "Loaded cv226_26692.txt\n",
      "Loaded cv561_9484.txt\n",
      "Loaded cv951_11816.txt\n",
      "Loaded cv495_16121.txt\n",
      "Loaded cv420_28631.txt\n",
      "Loaded cv761_13769.txt\n",
      "Loaded cv346_19198.txt\n",
      "Loaded cv106_18379.txt\n",
      "Loaded cv389_9611.txt\n",
      "Loaded cv488_21453.txt\n",
      "Loaded cv850_18185.txt\n",
      "Loaded cv129_18373.txt\n",
      "Loaded cv436_20564.txt\n",
      "Loaded cv032_23718.txt\n",
      "Loaded cv087_2145.txt\n",
      "Loaded cv075_6250.txt\n",
      "Loaded cv303_27366.txt\n",
      "Loaded cv970_19532.txt\n",
      "Loaded cv174_9735.txt\n",
      "Loaded cv700_23163.txt\n",
      "Loaded cv690_5425.txt\n",
      "Loaded cv781_5358.txt\n",
      "Loaded cv910_21930.txt\n",
      "Loaded cv571_29292.txt\n",
      "Loaded cv890_3515.txt\n",
      "Loaded cv047_18725.txt\n",
      "Loaded cv605_12730.txt\n",
      "Loaded cv454_21961.txt\n",
      "Loaded cv280_8651.txt\n",
      "Loaded cv869_24782.txt\n",
      "Loaded cv920_29423.txt\n",
      "Loaded cv414_11161.txt\n",
      "Loaded cv181_16083.txt\n",
      "Loaded cv433_10443.txt\n",
      "Loaded cv693_19147.txt\n",
      "Loaded cv472_29140.txt\n",
      "Loaded cv990_12443.txt\n",
      "Loaded cv675_22871.txt\n",
      "Loaded cv809_5012.txt\n",
      "Loaded cv232_16768.txt\n",
      "Loaded cv298_24487.txt\n",
      "Loaded cv787_15277.txt\n",
      "Loaded cv056_14663.txt\n",
      "Loaded cv404_21805.txt\n",
      "Loaded cv059_28723.txt\n",
      "Loaded cv451_11502.txt\n",
      "Loaded cv029_19943.txt\n",
      "Loaded cv016_4348.txt\n",
      "Loaded cv546_12723.txt\n",
      "Loaded cv286_26156.txt\n",
      "Loaded cv120_3793.txt\n",
      "Loaded cv061_9321.txt\n",
      "Loaded cv238_14285.txt\n",
      "Loaded cv143_21158.txt\n",
      "Loaded cv157_29302.txt\n",
      "Loaded cv624_11601.txt\n",
      "Loaded cv694_4526.txt\n",
      "Loaded cv757_10668.txt\n",
      "Loaded cv950_13478.txt\n",
      "Loaded cv562_10847.txt\n",
      "Loaded cv608_24647.txt\n",
      "Loaded cv241_24602.txt\n",
      "Loaded cv746_10471.txt\n",
      "Loaded cv889_22670.txt\n",
      "Loaded cv315_12638.txt\n",
      "Loaded cv829_21725.txt\n",
      "Loaded cv202_11382.txt\n",
      "Loaded cv796_17243.txt\n",
      "Loaded cv071_12969.txt\n",
      "Loaded cv082_11979.txt\n",
      "Loaded cv870_18090.txt\n",
      "Loaded cv043_16808.txt\n",
      "Loaded cv391_11615.txt\n",
      "Loaded cv380_8164.txt\n",
      "Loaded cv997_5152.txt\n",
      "Loaded cv998_15691.txt\n",
      "Loaded cv512_17618.txt\n",
      "Loaded cv640_5380.txt\n",
      "Loaded cv550_23226.txt\n",
      "Loaded cv548_18944.txt\n",
      "Loaded cv701_15880.txt\n",
      "Loaded cv954_19932.txt\n",
      "Loaded cv019_16117.txt\n",
      "Loaded cv039_5963.txt\n",
      "Loaded cv626_7907.txt\n",
      "Loaded cv689_13701.txt\n",
      "Loaded cv117_25625.txt\n",
      "Loaded cv518_14798.txt\n",
      "Loaded cv154_9562.txt\n",
      "Loaded cv148_18084.txt\n",
      "Loaded cv428_12202.txt\n",
      "Loaded cv177_10904.txt\n",
      "Loaded cv337_29061.txt\n",
      "Loaded cv374_26455.txt\n",
      "Loaded cv357_14710.txt\n",
      "Loaded cv169_24973.txt\n",
      "Loaded cv727_5006.txt\n",
      "Loaded cv861_12809.txt\n",
      "Loaded cv955_26154.txt\n",
      "Loaded cv982_22209.txt\n",
      "Loaded cv880_29629.txt\n",
      "Loaded cv792_3257.txt\n",
      "Loaded cv325_18330.txt\n",
      "Loaded cv741_12765.txt\n",
      "Loaded cv263_20693.txt\n",
      "Loaded cv539_21865.txt\n",
      "Loaded cv299_17950.txt\n",
      "Loaded cv400_20631.txt\n",
      "Loaded cv825_5168.txt\n",
      "Loaded cv597_26744.txt\n",
      "Loaded cv716_11153.txt\n",
      "Loaded cv996_12447.txt\n",
      "Loaded cv220_28906.txt\n",
      "Loaded cv820_24157.txt\n",
      "Loaded cv272_20313.txt\n",
      "Loaded cv682_17947.txt\n",
      "Loaded cv685_5710.txt\n",
      "Loaded cv978_22192.txt\n",
      "Loaded cv248_15672.txt\n",
      "Loaded cv233_17614.txt\n",
      "Loaded cv647_15275.txt\n",
      "Loaded cv698_16930.txt\n",
      "Loaded cv194_12855.txt\n",
      "Loaded cv806_9405.txt\n",
      "Loaded cv193_5393.txt\n",
      "Loaded cv405_21868.txt\n",
      "Loaded cv707_11421.txt\n",
      "Loaded cv072_5928.txt\n",
      "Loaded cv808_13773.txt\n",
      "Loaded cv147_22625.txt\n",
      "Loaded cv892_18788.txt\n",
      "Loaded cv267_16618.txt\n",
      "Loaded cv441_15276.txt\n",
      "Loaded cv259_11827.txt\n",
      "Loaded cv161_12224.txt\n",
      "Loaded cv896_17819.txt\n",
      "Loaded cv424_9268.txt\n",
      "Loaded cv908_17779.txt\n",
      "Loaded cv639_10797.txt\n",
      "Loaded cv338_9183.txt\n",
      "Loaded cv907_3193.txt\n",
      "Loaded cv574_23191.txt\n",
      "Loaded cv596_4367.txt\n",
      "Loaded cv477_23530.txt\n",
      "Loaded cv080_14899.txt\n",
      "Loaded cv385_29621.txt\n",
      "Loaded cv239_29828.txt\n",
      "Loaded cv246_28668.txt\n",
      "Loaded cv069_11613.txt\n",
      "Loaded cv079_12766.txt\n",
      "Loaded cv152_9052.txt\n",
      "Loaded cv672_27988.txt\n",
      "Loaded cv606_17672.txt\n",
      "Loaded cv419_14799.txt\n",
      "Loaded cv321_14191.txt\n",
      "Loaded cv917_29484.txt\n",
      "Loaded cv555_25047.txt\n",
      "Loaded cv008_29326.txt\n",
      "Loaded cv927_11471.txt\n",
      "Loaded cv231_11028.txt\n",
      "Loaded cv160_10848.txt\n",
      "Loaded cv953_7078.txt\n",
      "Loaded cv457_19546.txt\n",
      "Loaded cv237_20635.txt\n",
      "Loaded cv042_11927.txt\n",
      "Loaded cv742_8279.txt\n",
      "Loaded cv629_16604.txt\n",
      "Loaded cv783_14724.txt\n",
      "Loaded cv993_29565.txt\n",
      "Loaded cv935_24977.txt\n",
      "Loaded cv387_12391.txt\n",
      "Loaded cv972_26837.txt\n",
      "Loaded cv103_11943.txt\n",
      "Loaded cv142_23657.txt\n",
      "Loaded cv306_10859.txt\n",
      "Loaded cv995_23113.txt\n",
      "Loaded cv274_26379.txt\n",
      "Loaded cv949_21565.txt\n",
      "Loaded cv576_15688.txt\n",
      "Loaded cv721_28993.txt\n",
      "Loaded cv508_17742.txt\n",
      "Loaded cv104_19176.txt\n",
      "Loaded cv709_11173.txt\n",
      "Loaded cv723_9002.txt\n",
      "Loaded cv794_17353.txt\n",
      "Loaded cv985_5964.txt\n",
      "Loaded cv879_16585.txt\n",
      "Loaded cv831_16325.txt\n",
      "Loaded cv020_9234.txt\n",
      "Loaded cv785_23748.txt\n",
      "Loaded cv275_28725.txt\n",
      "Loaded cv842_5702.txt\n",
      "Loaded cv543_5107.txt\n",
      "Loaded cv532_6495.txt\n",
      "Loaded cv187_14112.txt\n",
      "Loaded cv011_13044.txt\n",
      "Loaded cv450_8319.txt\n",
      "Loaded cv247_14668.txt\n",
      "Loaded cv236_12427.txt\n",
      "Loaded cv827_19479.txt\n",
      "Loaded cv658_11186.txt\n",
      "Loaded cv712_24217.txt\n",
      "Loaded cv582_6678.txt\n",
      "Loaded cv030_22893.txt\n",
      "Loaded cv094_27868.txt\n",
      "Loaded cv786_23608.txt\n",
      "Loaded cv151_17231.txt\n",
      "Loaded cv364_14254.txt\n",
      "Loaded cv276_17126.txt\n",
      "Loaded cv945_13012.txt\n",
      "Loaded cv767_15673.txt\n",
      "Loaded cv167_18094.txt\n",
      "Loaded cv149_17084.txt\n",
      "Loaded cv158_10914.txt\n",
      "Loaded cv334_0074.txt\n",
      "Loaded cv956_12547.txt\n",
      "Loaded cv589_12853.txt\n",
      "Loaded cv680_10533.txt\n",
      "Loaded cv474_10682.txt\n",
      "Loaded cv354_8573.txt\n",
      "Loaded cv834_23192.txt\n",
      "Loaded cv649_13947.txt\n",
      "Loaded cv108_17064.txt\n",
      "Loaded cv268_20288.txt\n",
      "Loaded cv126_28821.txt\n",
      "Loaded cv912_5562.txt\n",
      "Loaded cv791_17995.txt\n",
      "Loaded cv311_17708.txt\n",
      "Loaded cv521_1730.txt\n",
      "Loaded cv697_12106.txt\n",
      "Loaded cv256_16529.txt\n",
      "Loaded cv463_10846.txt\n",
      "Loaded cv780_8467.txt\n",
      "Loaded cv406_22199.txt\n",
      "Loaded cv715_19246.txt\n",
      "Loaded cv456_20370.txt\n",
      "Loaded cv545_12848.txt\n",
      "Loaded cv728_17931.txt\n",
      "Loaded cv224_18875.txt\n",
      "Loaded cv586_8048.txt\n",
      "Loaded cv397_28890.txt\n",
      "Loaded cv984_14006.txt\n",
      "Loaded cv934_20426.txt\n",
      "Loaded cv578_16825.txt\n",
      "Loaded cv575_22598.txt\n",
      "Loaded cv737_28733.txt\n",
      "Loaded cv057_7962.txt\n",
      "Loaded cv631_4782.txt\n",
      "Loaded cv221_27081.txt\n",
      "Loaded cv262_13812.txt\n",
      "Loaded cv446_12209.txt\n",
      "Loaded cv013_10494.txt\n",
      "Loaded cv095_28730.txt\n",
      "Loaded cv833_11961.txt\n",
      "Loaded cv856_28882.txt\n",
      "Loaded cv215_23246.txt\n",
      "Loaded cv812_19051.txt\n",
      "Loaded cv875_5622.txt\n",
      "Loaded cv573_29384.txt\n",
      "Loaded cv281_24711.txt\n",
      "Loaded cv348_19207.txt\n",
      "Loaded cv734_22821.txt\n",
      "Loaded cv253_10190.txt\n",
      "Loaded cv636_16954.txt\n",
      "Loaded cv957_9059.txt\n",
      "Loaded cv145_12239.txt\n",
      "Loaded cv332_17997.txt\n",
      "Loaded cv802_28381.txt\n",
      "Loaded cv026_29229.txt\n",
      "Loaded cv810_13660.txt\n",
      "Loaded cv229_15200.txt\n",
      "Loaded cv014_15600.txt\n",
      "Loaded cv439_17633.txt\n",
      "Loaded cv422_9632.txt\n",
      "Loaded cv900_10800.txt\n",
      "Loaded cv530_17949.txt\n",
      "Loaded cv455_28866.txt\n",
      "Loaded cv204_8930.txt\n",
      "Loaded cv453_10911.txt\n",
      "Loaded cv625_13518.txt\n",
      "Loaded cv805_21128.txt\n",
      "Loaded cv471_18405.txt\n",
      "Loaded cv961_5578.txt\n",
      "Loaded cv425_8603.txt\n",
      "Loaded cv637_13682.txt\n",
      "Loaded cv826_12761.txt\n",
      "Loaded cv251_23901.txt\n",
      "Loaded cv788_26409.txt\n",
      "Loaded cv300_23302.txt\n",
      "Loaded cv567_29420.txt\n",
      "Loaded cv799_19812.txt\n",
      "Loaded cv222_18720.txt\n",
      "Loaded cv769_8565.txt\n",
      "Loaded cv552_0150.txt\n",
      "Loaded cv644_18551.txt\n",
      "Loaded cv540_3092.txt\n",
      "Loaded cv066_11668.txt\n",
      "Loaded cv153_11607.txt\n",
      "Loaded cv991_19973.txt\n",
      "Loaded cv852_27512.txt\n",
      "Loaded cv173_4295.txt\n",
      "Loaded cv365_12442.txt\n",
      "Loaded cv214_13285.txt\n",
      "Loaded cv077_23172.txt\n",
      "Loaded cv459_21834.txt\n",
      "Loaded cv620_2556.txt\n",
      "Loaded cv673_25874.txt\n",
      "Loaded cv722_7571.txt\n",
      "Loaded cv992_12806.txt\n",
      "Loaded cv733_9891.txt\n",
      "Loaded cv807_23024.txt\n",
      "Loaded cv511_10360.txt\n",
      "Loaded cv118_28837.txt\n",
      "Loaded cv942_18509.txt\n",
      "Loaded cv577_28220.txt\n",
      "Loaded cv898_1576.txt\n",
      "Loaded cv598_18184.txt\n",
      "Loaded cv083_25491.txt\n",
      "Loaded cv290_11981.txt\n",
      "Loaded cv678_14887.txt\n",
      "Loaded cv135_12506.txt\n",
      "Loaded cv588_14467.txt\n",
      "Loaded cv654_19345.txt\n",
      "Loaded cv018_21672.txt\n",
      "Loaded cv048_18380.txt\n",
      "Loaded cv207_29141.txt\n",
      "Loaded cv096_12262.txt\n",
      "Loaded cv516_12117.txt\n",
      "Loaded cv369_14245.txt\n",
      "Loaded cv345_9966.txt\n",
      "Loaded cv695_22268.txt\n",
      "Loaded cv484_26169.txt\n",
      "Loaded cv339_22452.txt\n",
      "Loaded cv001_19502.txt\n",
      "Loaded cv163_10110.txt\n",
      "Loaded cv581_20790.txt\n",
      "Loaded cv277_20467.txt\n",
      "Loaded cv358_11557.txt\n",
      "Loaded cv469_21998.txt\n",
      "Loaded cv642_29788.txt\n",
      "Loaded cv976_10724.txt\n",
      "Loaded cv244_22935.txt\n",
      "Loaded cv058_8469.txt\n",
      "Loaded cv307_26382.txt\n",
      "Loaded cv305_9937.txt\n",
      "Loaded cv355_18174.txt\n",
      "Loaded cv772_12971.txt\n",
      "Loaded cv750_10606.txt\n",
      "Loaded cv243_22164.txt\n",
      "Loaded cv764_12701.txt\n",
      "Loaded cv674_11593.txt\n",
      "Loaded cv980_11851.txt\n",
      "Loaded cv351_17029.txt\n",
      "Loaded cv111_12253.txt\n",
      "Loaded cv551_11214.txt\n",
      "Loaded cv402_16097.txt\n",
      "Loaded cv871_25971.txt\n",
      "Loaded cv878_17204.txt\n",
      "Loaded cv989_17297.txt\n",
      "Loaded cv719_5581.txt\n",
      "Loaded cv084_15183.txt\n",
      "Loaded cv188_20687.txt\n",
      "Loaded cv766_7983.txt\n",
      "Loaded cv857_17527.txt\n",
      "Loaded cv340_14776.txt\n",
      "Loaded cv872_13710.txt\n",
      "Loaded cv771_28466.txt\n",
      "Loaded cv230_7913.txt\n",
      "Loaded cv559_0057.txt\n",
      "Loaded cv266_26644.txt\n",
      "Loaded cv125_9636.txt\n",
      "Loaded cv566_8967.txt\n",
      "Loaded cv628_20758.txt\n",
      "Loaded cv218_25651.txt\n",
      "Loaded cv353_19197.txt\n",
      "Loaded cv417_14653.txt\n",
      "Loaded cv999_14636.txt\n",
      "Loaded cv265_11625.txt\n",
      "Loaded cv462_20788.txt\n",
      "Loaded cv093_15606.txt\n",
      "Loaded cv897_11703.txt\n",
      "Loaded cv899_17812.txt\n",
      "Loaded cv068_14810.txt\n",
      "Loaded cv536_27221.txt\n",
      "Loaded cv568_17065.txt\n",
      "Loaded cv940_18935.txt\n",
      "Loaded cv399_28593.txt\n",
      "Loaded cv438_8500.txt\n",
      "Loaded cv683_13047.txt\n",
      "Loaded cv211_9955.txt\n",
      "Loaded cv663_14484.txt\n",
      "Loaded cv662_14791.txt\n",
      "Loaded cv245_8938.txt\n",
      "Loaded cv116_28734.txt\n",
      "Loaded cv594_11945.txt\n",
      "Loaded cv099_11189.txt\n",
      "Loaded cv427_11693.txt\n",
      "Loaded cv510_24758.txt\n",
      "Loaded cv373_21872.txt\n",
      "Loaded cv590_20712.txt\n",
      "Loaded cv657_25835.txt\n",
      "Loaded cv952_26375.txt\n",
      "Loaded cv570_28960.txt\n",
      "Loaded cv219_19874.txt\n",
      "Loaded cv199_9721.txt\n",
      "Loaded cv895_22200.txt\n",
      "Loaded cv967_5626.txt\n",
      "Loaded cv480_21195.txt\n",
      "Loaded cv533_9843.txt\n",
      "Loaded cv958_13020.txt\n",
      "Loaded cv840_18033.txt\n",
      "Loaded cv046_10613.txt\n",
      "Loaded cv743_17023.txt\n",
      "Loaded cv190_27176.txt\n",
      "Loaded cv544_5301.txt\n",
      "Loaded cv342_20917.txt\n",
      "Loaded cv213_20300.txt\n",
      "Loaded cv613_23104.txt\n",
      "Loaded cv868_12799.txt\n",
      "Loaded cv813_6649.txt\n",
      "Loaded cv648_17277.txt\n",
      "Loaded cv811_22646.txt\n",
      "Loaded cv800_13494.txt\n",
      "Loaded cv717_17472.txt\n",
      "Loaded cv336_10363.txt\n",
      "Loaded cv408_5367.txt\n",
      "Loaded cv136_12384.txt\n",
      "Loaded cv859_15689.txt\n",
      "Loaded cv051_10751.txt\n",
      "Loaded cv164_23451.txt\n",
      "Loaded cv587_20532.txt\n",
      "Loaded cv595_26420.txt\n",
      "Loaded cv974_24303.txt\n",
      "Loaded cv814_20316.txt\n",
      "Loaded cv765_20429.txt\n",
      "Loaded cv363_29273.txt\n",
      "Loaded cv881_14767.txt\n",
      "Loaded cv278_14533.txt\n",
      "Loaded cv060_11754.txt\n",
      "Loaded cv504_29120.txt\n",
      "Loaded cv470_17444.txt\n",
      "Loaded cv017_23487.txt\n",
      "Loaded cv666_20301.txt\n",
      "Loaded cv031_19540.txt\n",
      "Loaded cv301_13010.txt\n",
      "Loaded cv599_22197.txt\n",
      "Loaded cv494_18689.txt\n",
      "Loaded cv843_17054.txt\n",
      "Loaded cv906_12332.txt\n",
      "Loaded cv331_8656.txt\n",
      "Loaded cv591_24887.txt\n",
      "Loaded cv021_17313.txt\n",
      "Loaded cv832_24713.txt\n",
      "Loaded cv919_18155.txt\n",
      "Loaded cv090_0049.txt\n",
      "Loaded cv182_7791.txt\n",
      "Loaded cv760_8977.txt\n",
      "Loaded cv395_11761.txt\n",
      "Loaded cv092_27987.txt\n",
      "Loaded cv172_12037.txt\n",
      "Loaded cv503_11196.txt\n",
      "Loaded cv873_19937.txt\n",
      "Loaded cv981_16679.txt\n",
      "Loaded cv209_28973.txt\n",
      "Loaded cv269_23018.txt\n",
      "Loaded cv432_15873.txt\n",
      "Loaded cv418_16562.txt\n",
      "Loaded cv659_21483.txt\n",
      "Loaded cv528_11669.txt\n",
      "Loaded cv293_29731.txt\n",
      "Loaded cv249_12674.txt\n",
      "Loaded cv877_29132.txt\n",
      "Loaded cv903_18981.txt\n",
      "Loaded cv818_10698.txt\n",
      "Loaded cv119_9909.txt\n",
      "Loaded cv635_0984.txt\n",
      "Loaded cv774_15488.txt\n",
      "Loaded cv478_15921.txt\n",
      "Loaded cv660_23140.txt\n",
      "Loaded cv110_27832.txt\n",
      "Loaded cv052_29318.txt\n",
      "Loaded cv314_16095.txt\n",
      "Loaded cv669_24318.txt\n",
      "Loaded cv804_11763.txt\n",
      "Loaded cv711_12687.txt\n",
      "Loaded cv524_24885.txt\n",
      "Loaded cv468_16844.txt\n",
      "Loaded cv846_29359.txt\n",
      "Loaded cv329_29293.txt\n",
      "Loaded cv677_18938.txt\n",
      "Loaded cv064_25842.txt\n",
      "Loaded cv078_16506.txt\n",
      "Loaded cv473_7869.txt\n",
      "Loaded cv328_10908.txt\n",
      "Loaded cv977_4776.txt\n",
      "Loaded cv966_28671.txt\n",
      "Loaded cv309_23737.txt\n",
      "Loaded cv076_26009.txt\n",
      "Loaded cv797_7245.txt\n",
      "Loaded cv444_9975.txt\n",
      "Loaded cv375_9932.txt\n",
      "Loaded cv911_21695.txt\n",
      "Loaded cv557_12237.txt\n",
      "Loaded cv505_12926.txt\n",
      "Loaded cv178_14380.txt\n",
      "Loaded cv186_2396.txt\n",
      "Loaded cv360_8927.txt\n",
      "Loaded cv668_18848.txt\n",
      "Loaded cv316_5972.txt\n",
      "Loaded cv323_29633.txt\n",
      "Loaded cv696_29619.txt\n",
      "Loaded cv449_9126.txt\n",
      "Loaded cv124_3903.txt\n",
      "Loaded cv396_19127.txt\n",
      "Loaded cv100_12406.txt\n",
      "Loaded cv156_11119.txt\n",
      "Loaded cv652_15653.txt\n",
      "Loaded cv500_10722.txt\n",
      "Loaded cv045_25077.txt\n",
      "Loaded cv383_14662.txt\n",
      "Loaded cv304_28489.txt\n",
      "Loaded cv619_13677.txt\n",
      "Loaded cv732_13092.txt\n",
      "Loaded cv261_11855.txt\n",
      "Loaded cv538_28485.txt\n",
      "Loaded cv726_4365.txt\n",
      "Loaded cv476_18402.txt\n",
      "Loaded cv616_29187.txt\n",
      "Loaded cv372_6654.txt\n",
      "Loaded cv973_10171.txt\n",
      "Loaded cv603_18885.txt\n",
      "Loaded cv817_3675.txt\n",
      "Loaded cv515_18484.txt\n",
      "Loaded cv864_3087.txt\n",
      "Loaded cv901_11934.txt\n",
      "Loaded cv070_13249.txt\n",
      "Loaded cv916_17034.txt\n",
      "Loaded cv751_17208.txt\n",
      "Loaded cv720_5383.txt\n",
      "Loaded cv361_28738.txt\n",
      "Loaded cv196_28898.txt\n",
      "Loaded cv670_2666.txt\n",
      "Loaded cv517_20616.txt\n",
      "Loaded cv343_10906.txt\n",
      "Loaded cv621_15984.txt\n",
      "Loaded cv333_9443.txt\n",
      "Loaded cv793_15235.txt\n",
      "Loaded cv848_10061.txt\n",
      "Loaded cv041_22364.txt\n",
      "Loaded cv367_24065.txt\n",
      "Loaded cv509_17354.txt\n",
      "Loaded cv133_18065.txt\n",
      "Loaded cv130_18521.txt\n",
      "Loaded cv242_11354.txt\n",
      "Loaded cv724_15265.txt\n",
      "Loaded cv285_18186.txt\n",
      "Loaded cv132_5423.txt\n",
      "Loaded cv381_21673.txt\n",
      "Loaded cv403_6721.txt\n",
      "Loaded cv452_5179.txt\n",
      "Loaded cv284_20530.txt\n",
      "Loaded cv830_5778.txt\n",
      "Loaded cv138_13903.txt\n",
      "Loaded cv183_19826.txt\n",
      "Loaded cv863_7912.txt\n",
      "Loaded cv431_7538.txt\n",
      "Loaded cv924_29397.txt\n",
      "Loaded cv779_18989.txt\n",
      "Loaded cv250_26462.txt\n",
      "Loaded cv434_5641.txt\n",
      "Loaded cv593_11931.txt\n",
      "Loaded cv994_13229.txt\n",
      "Loaded cv197_29271.txt\n",
      "Loaded cv661_25780.txt\n",
      "Loaded cv513_7236.txt\n",
      "Loaded cv175_7375.txt\n",
      "Loaded cv407_23928.txt\n",
      "Loaded cv968_25413.txt\n",
      "Loaded cv413_7893.txt\n",
      "Loaded cv466_20092.txt\n",
      "Loaded cv928_9478.txt\n",
      "Loaded cv062_24556.txt\n",
      "Loaded cv874_12182.txt\n",
      "Loaded cv005_29357.txt\n",
      "Loaded cv653_2107.txt\n",
      "Loaded cv273_28961.txt\n",
      "Loaded cv565_29403.txt\n",
      "Loaded cv443_22367.txt\n",
      "Loaded cv412_25254.txt\n",
      "Loaded cv855_22134.txt\n",
      "Loaded cv882_10042.txt\n",
      "Loaded cv002_17424.txt\n",
      "Loaded cv481_7930.txt\n",
      "Loaded cv191_29539.txt\n",
      "Loaded cv235_10704.txt\n",
      "Loaded cv000_29416.txt\n",
      "Loaded cv086_19488.txt\n",
      "Loaded cv067_21192.txt\n",
      "Loaded cv569_26750.txt\n",
      "Loaded cv821_29283.txt\n",
      "Loaded cv091_7899.txt\n",
      "Loaded cv486_9788.txt\n",
      "Loaded cv255_15267.txt\n",
      "Loaded cv159_29374.txt\n",
      "Loaded cv085_15286.txt\n",
      "Loaded cv081_18241.txt\n",
      "Loaded cv012_29411.txt\n",
      "Loaded cv252_24974.txt\n"
     ]
    }
   ],
   "source": [
    "#Step2: We have two directories each with 1,000 documents each. We can process each directory in turn by first getting\n",
    "#a list of files in the directory using the listdir() function, then loading each file in turn.\n",
    "#For example, we can load each document in the negative directory using the load_doc() function to \n",
    "#do the actual loading\n",
    "\n",
    "from os import listdir\n",
    "# load all docs in a directory\n",
    "def process_docs(directory):\n",
    "\t# walk through all files in the folder\n",
    "\tfor filename in listdir(directory):\n",
    "\t\t# skip files that do not have the right extension\n",
    "\t\tif not filename.endswith(\".txt\"):\n",
    "\t\t\tcontinue\n",
    "\t\t# create the full path of the file to open\n",
    "\t\tpath = directory + '/' + filename\n",
    "\t\t# load document\n",
    "\t\tdoc = load_doc(path)\n",
    "\t\tprint('Loaded %s' % filename)\n",
    " \n",
    "# specify directory to load\n",
    "directory = '/Users/hasanuzz/Desktop/review_data/txt_sentoken/neg'\n",
    "process_docs(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', \"what's\", 'the', 'deal', '?', 'watch', 'the', 'movie', 'and', '\"', 'sorta', '\"', 'find', 'out', '.', '.', '.', 'critique', ':', 'a', 'mind-fuck', 'movie', 'for', 'the', 'teen', 'generation', 'that', 'touches', 'on', 'a', 'very', 'cool', 'idea', ',', 'but', 'presents', 'it', 'in', 'a', 'very', 'bad', 'package', '.', 'which', 'is', 'what', 'makes', 'this', 'review', 'an', 'even', 'harder', 'one', 'to', 'write', ',', 'since', 'i', 'generally', 'applaud', 'films', 'which', 'attempt', 'to', 'break', 'the', 'mold', ',', 'mess', 'with', 'your', 'head', 'and', 'such', '(', 'lost', 'highway', '&', 'memento', ')', ',', 'but', 'there', 'are', 'good', 'and', 'bad', 'ways', 'of', 'making', 'all', 'types', 'of', 'films', ',', 'and', 'these', 'folks', 'just', \"didn't\", 'snag', 'this', 'one', 'correctly', '.', 'they', 'seem', 'to', 'have', 'taken', 'this', 'pretty', 'neat', 'concept', ',', 'but', 'executed', 'it', 'terribly', '.', 'so', 'what', 'are', 'the', 'problems', 'with', 'the', 'movie', '?', 'well', ',', 'its', 'main', 'problem', 'is', 'that', \"it's\", 'simply', 'too', 'jumbled', '.', 'it', 'starts', 'off', '\"', 'normal', '\"', 'but', 'then', 'downshifts', 'into', 'this', '\"', 'fantasy', '\"', 'world', 'in', 'which', 'you', ',', 'as', 'an', 'audience', 'member', ',', 'have', 'no', 'idea', \"what's\", 'going', 'on', '.', 'there', 'are', 'dreams', ',', 'there', 'are', 'characters', 'coming', 'back', 'from', 'the', 'dead', ',', 'there', 'are', 'others', 'who', 'look', 'like', 'the', 'dead', ',', 'there', 'are', 'strange', 'apparitions', ',', 'there', 'are', 'disappearances', ',', 'there', 'are', 'a', 'looooot', 'of', 'chase', 'scenes', ',', 'there', 'are', 'tons', 'of', 'weird', 'things', 'that', 'happen', ',', 'and', 'most', 'of', 'it', 'is', 'simply', 'not', 'explained', '.', 'now', 'i', 'personally', \"don't\", 'mind', 'trying', 'to', 'unravel', 'a', 'film', 'every', 'now', 'and', 'then', ',', 'but', 'when', 'all', 'it', 'does', 'is', 'give', 'me', 'the', 'same', 'clue', 'over', 'and', 'over', 'again', ',', 'i', 'get', 'kind', 'of', 'fed', 'up', 'after', 'a', 'while', ',', 'which', 'is', 'this', \"film's\", 'biggest', 'problem', '.', \"it's\", 'obviously', 'got', 'this', 'big', 'secret', 'to', 'hide', ',', 'but', 'it', 'seems', 'to', 'want', 'to', 'hide', 'it', 'completely', 'until', 'its', 'final', 'five', 'minutes', '.', 'and', 'do', 'they', 'make', 'things', 'entertaining', ',', 'thrilling', 'or', 'even', 'engaging', ',', 'in', 'the', 'meantime', '?', 'not', 'really', '.', 'the', 'sad', 'part', 'is', 'that', 'the', 'arrow', 'and', 'i', 'both', 'dig', 'on', 'flicks', 'like', 'this', ',', 'so', 'we', 'actually', 'figured', 'most', 'of', 'it', 'out', 'by', 'the', 'half-way', 'point', ',', 'so', 'all', 'of', 'the', 'strangeness', 'after', 'that', 'did', 'start', 'to', 'make', 'a', 'little', 'bit', 'of', 'sense', ',', 'but', 'it', 'still', \"didn't\", 'the', 'make', 'the', 'film', 'all', 'that', 'more', 'entertaining', '.', 'i', 'guess', 'the', 'bottom', 'line', 'with', 'movies', 'like', 'this', 'is', 'that', 'you', 'should', 'always', 'make', 'sure', 'that', 'the', 'audience', 'is', '\"', 'into', 'it', '\"', 'even', 'before', 'they', 'are', 'given', 'the', 'secret', 'password', 'to', 'enter', 'your', 'world', 'of', 'understanding', '.', 'i', 'mean', ',', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'from', 'visions', 'for', 'about', '20', 'minutes', 'throughout', 'the', 'movie', 'is', 'just', 'plain', 'lazy', '!', '!', 'okay', ',', 'we', 'get', 'it', '.', '.', '.', 'there', 'are', 'people', 'chasing', 'her', 'and', 'we', \"don't\", 'know', 'who', 'they', 'are', '.', 'do', 'we', 'really', 'need', 'to', 'see', 'it', 'over', 'and', 'over', 'again', '?', 'how', 'about', 'giving', 'us', 'different', 'scenes', 'offering', 'further', 'insight', 'into', 'all', 'of', 'the', 'strangeness', 'going', 'down', 'in', 'the', 'movie', '?', 'apparently', ',', 'the', 'studio', 'took', 'this', 'film', 'away', 'from', 'its', 'director', 'and', 'chopped', 'it', 'up', 'themselves', ',', 'and', 'it', 'shows', '.', 'there', \"might've\", 'been', 'a', 'pretty', 'decent', 'teen', 'mind-fuck', 'movie', 'in', 'here', 'somewhere', ',', 'but', 'i', 'guess', '\"', 'the', 'suits', '\"', 'decided', 'that', 'turning', 'it', 'into', 'a', 'music', 'video', 'with', 'little', 'edge', ',', 'would', 'make', 'more', 'sense', '.', 'the', 'actors', 'are', 'pretty', 'good', 'for', 'the', 'most', 'part', ',', 'although', 'wes', 'bentley', 'just', 'seemed', 'to', 'be', 'playing', 'the', 'exact', 'same', 'character', 'that', 'he', 'did', 'in', 'american', 'beauty', ',', 'only', 'in', 'a', 'new', 'neighborhood', '.', 'but', 'my', 'biggest', 'kudos', 'go', 'out', 'to', 'sagemiller', ',', 'who', 'holds', 'her', 'own', 'throughout', 'the', 'entire', 'film', ',', 'and', 'actually', 'has', 'you', 'feeling', 'her', \"character's\", 'unraveling', '.', 'overall', ',', 'the', 'film', \"doesn't\", 'stick', 'because', 'it', \"doesn't\", 'entertain', ',', \"it's\", 'confusing', ',', 'it', 'rarely', 'excites', 'and', 'it', 'feels', 'pretty', 'redundant', 'for', 'most', 'of', 'its', 'runtime', ',', 'despite', 'a', 'pretty', 'cool', 'ending', 'and', 'explanation', 'to', 'all', 'of', 'the', 'craziness', 'that', 'came', 'before', 'it', '.', 'oh', ',', 'and', 'by', 'the', 'way', ',', 'this', 'is', 'not', 'a', 'horror', 'or', 'teen', 'slasher', 'flick', '.', '.', '.', \"it's\", 'just', 'packaged', 'to', 'look', 'that', 'way', 'because', 'someone', 'is', 'apparently', 'assuming', 'that', 'the', 'genre', 'is', 'still', 'hot', 'with', 'the', 'kids', '.', 'it', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'and', 'has', 'been', 'sitting', 'on', 'the', 'shelves', 'ever', 'since', '.', 'whatever', '.', '.', '.', 'skip', 'it', '!', \"where's\", 'joblo', 'coming', 'from', '?', 'a', 'nightmare', 'of', 'elm', 'street', '3', '(', '7/10', ')', '-', 'blair', 'witch', '2', '(', '7/10', ')', '-', 'the', 'crow', '(', '9/10', ')', '-', 'the', 'crow', ':', 'salvation', '(', '4/10', ')', '-', 'lost', 'highway', '(', '10/10', ')', '-', 'memento', '(', '10/10', ')', '-', 'the', 'others', '(', '9/10', ')', '-', 'stir', 'of', 'echoes', '(', '8/10', ')']\n"
     ]
    }
   ],
   "source": [
    "#Step3: Clean Text Data\n",
    "\n",
    "#We will assume that we will be using a bag-of-words model or perhaps a word embedding that does not require \n",
    "#too much preparation.\n",
    "\n",
    "#Split into Tokens\n",
    "\n",
    "#First, let’s load one document and look at the raw tokens split by white space. \n",
    "#We will use the load_doc() function developed in the previous section. We can use the split() \n",
    "#function to split the loaded document into tokens separated by white space.\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# load the document\n",
    "filename = '/Users/hasanuzz/Desktop/review_data/txt_sentoken/neg/cv000_29416.txt'\n",
    "text = load_doc(filename)\n",
    "# split into tokens by white space\n",
    "tokens = text.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plot', 'two', 'teen', 'couples', 'go', 'church', 'party', 'drink', 'drive', 'get', 'accident', 'one', 'guys', 'dies', 'girlfriend', 'continues', 'see', 'life', 'nightmares', 'whats', 'deal', 'watch', 'movie', 'sorta', 'find', 'critique', 'mindfuck', 'movie', 'teen', 'generation', 'touches', 'cool', 'idea', 'presents', 'bad', 'package', 'makes', 'review', 'even', 'harder', 'one', 'write', 'since', 'generally', 'applaud', 'films', 'attempt', 'break', 'mold', 'mess', 'head', 'lost', 'highway', 'memento', 'good', 'bad', 'ways', 'making', 'types', 'films', 'folks', 'didnt', 'snag', 'one', 'correctly', 'seem', 'taken', 'pretty', 'neat', 'concept', 'executed', 'terribly', 'problems', 'movie', 'well', 'main', 'problem', 'simply', 'jumbled', 'starts', 'normal', 'downshifts', 'fantasy', 'world', 'audience', 'member', 'idea', 'whats', 'going', 'dreams', 'characters', 'coming', 'back', 'dead', 'others', 'look', 'like', 'dead', 'strange', 'apparitions', 'disappearances', 'looooot', 'chase', 'scenes', 'tons', 'weird', 'things', 'happen', 'simply', 'explained', 'personally', 'dont', 'mind', 'trying', 'unravel', 'film', 'every', 'give', 'clue', 'get', 'kind', 'fed', 'films', 'biggest', 'problem', 'obviously', 'got', 'big', 'secret', 'hide', 'seems', 'want', 'hide', 'completely', 'final', 'five', 'minutes', 'make', 'things', 'entertaining', 'thrilling', 'even', 'engaging', 'meantime', 'really', 'sad', 'part', 'arrow', 'dig', 'flicks', 'like', 'actually', 'figured', 'halfway', 'point', 'strangeness', 'start', 'make', 'little', 'bit', 'sense', 'still', 'didnt', 'make', 'film', 'entertaining', 'guess', 'bottom', 'line', 'movies', 'like', 'always', 'make', 'sure', 'audience', 'even', 'given', 'secret', 'password', 'enter', 'world', 'understanding', 'mean', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'visions', 'minutes', 'throughout', 'movie', 'plain', 'lazy', 'okay', 'get', 'people', 'chasing', 'dont', 'know', 'really', 'need', 'see', 'giving', 'us', 'different', 'scenes', 'offering', 'insight', 'strangeness', 'going', 'movie', 'apparently', 'studio', 'took', 'film', 'away', 'director', 'chopped', 'shows', 'mightve', 'pretty', 'decent', 'teen', 'mindfuck', 'movie', 'somewhere', 'guess', 'suits', 'decided', 'turning', 'music', 'video', 'little', 'edge', 'would', 'make', 'sense', 'actors', 'pretty', 'good', 'part', 'although', 'wes', 'bentley', 'seemed', 'playing', 'exact', 'character', 'american', 'beauty', 'new', 'neighborhood', 'biggest', 'kudos', 'go', 'sagemiller', 'holds', 'throughout', 'entire', 'film', 'actually', 'feeling', 'characters', 'unraveling', 'overall', 'film', 'doesnt', 'stick', 'doesnt', 'entertain', 'confusing', 'rarely', 'excites', 'feels', 'pretty', 'redundant', 'runtime', 'despite', 'pretty', 'cool', 'ending', 'explanation', 'craziness', 'came', 'oh', 'way', 'horror', 'teen', 'slasher', 'flick', 'packaged', 'look', 'way', 'someone', 'apparently', 'assuming', 'genre', 'still', 'hot', 'kids', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'sitting', 'shelves', 'ever', 'since', 'whatever', 'skip', 'wheres', 'joblo', 'coming', 'nightmare', 'elm', 'street', 'blair', 'witch', 'crow', 'crow', 'salvation', 'lost', 'highway', 'memento', 'others', 'stir', 'echoes']\n"
     ]
    }
   ],
   "source": [
    "#Step3 Continues: We could do various things to clean the data such as \n",
    "\n",
    "# Remove punctuation from words (e.g. ‘what’s’).\n",
    "# Removing tokens that are just punctuation (e.g. ‘-‘).\n",
    "# Removing tokens that contain numbers (e.g. ’10/10′).\n",
    "# Remove tokens that have one character (e.g. ‘a’).\n",
    "# Remove tokens that don’t have much meaning (e.g. ‘and’)\n",
    "\n",
    "# Some ideas:\n",
    "\n",
    "# We can filter out punctuation from tokens using the string translate() function.\n",
    "# We can remove tokens that are just punctuation or contain numbers by using an isalpha() check on each token.\n",
    "# We can remove English stop words using the list loaded using NLTK.\n",
    "# We can filter out short tokens by checking their length.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# load the document\n",
    "filename = '/Users/hasanuzz/Desktop/review_data/txt_sentoken/neg/cv000_29416.txt'\n",
    "text = load_doc(filename)\n",
    "# split into tokens by white space\n",
    "tokens = text.split()\n",
    "# remove punctuation from each token\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "tokens = [w.translate(table) for w in tokens]\n",
    "# remove remaining tokens that are not alphabetic\n",
    "tokens = [word for word in tokens if word.isalpha()]\n",
    "# filter out stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [w for w in tokens if not w in stop_words]\n",
    "# filter out short tokens\n",
    "tokens = [word for word in tokens if len(word) > 1]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['films', 'adapted', 'comic', 'books', 'plenty', 'success', 'whether', 'theyre', 'superheroes', 'batman', 'superman', 'spawn', 'geared', 'toward', 'kids', 'casper', 'arthouse', 'crowd', 'ghost', 'world', 'theres', 'never', 'really', 'comic', 'book', 'like', 'hell', 'starters', 'created', 'alan', 'moore', 'eddie', 'campbell', 'brought', 'medium', 'whole', 'new', 'level', 'mid', 'series', 'called', 'watchmen', 'say', 'moore', 'campbell', 'thoroughly', 'researched', 'subject', 'jack', 'ripper', 'would', 'like', 'saying', 'michael', 'jackson', 'starting', 'look', 'little', 'odd', 'book', 'graphic', 'novel', 'pages', 'long', 'includes', 'nearly', 'consist', 'nothing', 'footnotes', 'words', 'dont', 'dismiss', 'film', 'source', 'get', 'past', 'whole', 'comic', 'book', 'thing', 'might', 'find', 'another', 'stumbling', 'block', 'hells', 'directors', 'albert', 'allen', 'hughes', 'getting', 'hughes', 'brothers', 'direct', 'seems', 'almost', 'ludicrous', 'casting', 'carrot', 'top', 'well', 'anything', 'riddle', 'better', 'direct', 'film', 'thats', 'set', 'ghetto', 'features', 'really', 'violent', 'street', 'crime', 'mad', 'geniuses', 'behind', 'menace', 'ii', 'society', 'ghetto', 'question', 'course', 'whitechapel', 'londons', 'east', 'end', 'filthy', 'sooty', 'place', 'whores', 'called', 'unfortunates', 'starting', 'get', 'little', 'nervous', 'mysterious', 'psychopath', 'carving', 'profession', 'surgical', 'precision', 'first', 'stiff', 'turns', 'copper', 'peter', 'godley', 'robbie', 'coltrane', 'world', 'enough', 'calls', 'inspector', 'frederick', 'abberline', 'johnny', 'depp', 'blow', 'crack', 'case', 'abberline', 'widower', 'prophetic', 'dreams', 'unsuccessfully', 'tries', 'quell', 'copious', 'amounts', 'absinthe', 'opium', 'upon', 'arriving', 'whitechapel', 'befriends', 'unfortunate', 'named', 'mary', 'kelly', 'heather', 'graham', 'say', 'isnt', 'proceeds', 'investigate', 'horribly', 'gruesome', 'crimes', 'even', 'police', 'surgeon', 'cant', 'stomach', 'dont', 'think', 'anyone', 'needs', 'briefed', 'jack', 'ripper', 'wont', 'go', 'particulars', 'say', 'moore', 'campbell', 'unique', 'interesting', 'theory', 'identity', 'killer', 'reasons', 'chooses', 'slay', 'comic', 'dont', 'bother', 'cloaking', 'identity', 'ripper', 'screenwriters', 'terry', 'hayes', 'vertical', 'limit', 'rafael', 'yglesias', 'les', 'mis', 'rables', 'good', 'job', 'keeping', 'hidden', 'viewers', 'end', 'funny', 'watch', 'locals', 'blindly', 'point', 'finger', 'blame', 'jews', 'indians', 'englishman', 'could', 'never', 'capable', 'committing', 'ghastly', 'acts', 'hells', 'ending', 'whistling', 'stonecutters', 'song', 'simpsons', 'days', 'holds', 'back', 'electric', 'carwho', 'made', 'steve', 'guttenberg', 'star', 'dont', 'worry', 'itll', 'make', 'sense', 'see', 'onto', 'hells', 'appearance', 'certainly', 'dark', 'bleak', 'enough', 'surprising', 'see', 'much', 'looks', 'like', 'tim', 'burton', 'film', 'planet', 'apes', 'times', 'seems', 'like', 'sleepy', 'hollow', 'print', 'saw', 'wasnt', 'completely', 'finished', 'color', 'music', 'finalized', 'comments', 'marilyn', 'manson', 'cinematographer', 'peter', 'deming', 'dont', 'say', 'word', 'ably', 'captures', 'dreariness', 'victorianera', 'london', 'helped', 'make', 'flashy', 'killing', 'scenes', 'remind', 'crazy', 'flashbacks', 'twin', 'peaks', 'even', 'though', 'violence', 'film', 'pales', 'comparison', 'blackandwhite', 'comic', 'oscar', 'winner', 'martin', 'childs', 'shakespeare', 'love', 'production', 'design', 'turns', 'original', 'prague', 'surroundings', 'one', 'creepy', 'place', 'even', 'acting', 'hell', 'solid', 'dreamy', 'depp', 'turning', 'typically', 'strong', 'performance', 'deftly', 'handling', 'british', 'accent', 'ians', 'holm', 'joe', 'goulds', 'secret', 'richardson', 'dalmatians', 'log', 'great', 'supporting', 'roles', 'big', 'surprise', 'graham', 'cringed', 'first', 'time', 'opened', 'mouth', 'imagining', 'attempt', 'irish', 'accent', 'actually', 'wasnt', 'half', 'bad', 'film', 'however', 'good', 'strong', 'violencegore', 'sexuality', 'language', 'drug', 'content']\n"
     ]
    }
   ],
   "source": [
    "#Step3 Continues:\n",
    "# We can put the above block into a function called clean_doc() and test it on another review, this time a positive review.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "\t# split into tokens by white space\n",
    "\ttokens = doc.split()\n",
    "\t# remove punctuation from each token\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\ttokens = [w.translate(table) for w in tokens]\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "\ttokens = [word for word in tokens if word.isalpha()]\n",
    "\t# filter out stop words\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\ttokens = [w for w in tokens if not w in stop_words]\n",
    "\t# filter out short tokens\n",
    "\ttokens = [word for word in tokens if len(word) > 1]\n",
    "\treturn tokens\n",
    "\n",
    "# load the document\n",
    "filename = '/Users/hasanuzz/Desktop/review_data/txt_sentoken/pos/cv000_29590.txt'\n",
    "text = load_doc(filename)\n",
    "tokens = clean_doc(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step4: Develop Vocabulary \n",
    "\n",
    "# We need to develop a new function to process a document and add it to the vocabulary. The function needs to load a\n",
    "# document by calling the previously developed load_doc() function. It needs to clean the loaded document using the \n",
    "# previously developed clean_doc() function, then it needs to add all the tokens to the Counter (it is a function), \n",
    "# and update counts. We can do this last step by calling the update() function on the counter object.\n",
    "\n",
    "#  add_doc_to_vocab() a function that takes as arguments a document filename and a Counter vocabulary.\n",
    "\n",
    "# load doc and add to vocab\n",
    "def add_doc_to_vocab(filename, vocab):\n",
    "\t# load doc\n",
    "\tdoc = load_doc(filename)\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(doc)\n",
    "\t# update counts\n",
    "\tvocab.update(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Step4: Develop Vocabulary (continues)\n",
    "# Finally, we can use our template above for processing all documents in a directory called process_docs() and update \n",
    "# it to call add_doc_to_vocab()\n",
    "\n",
    "# load all docs in a directory\n",
    "def process_docs(directory, vocab):\n",
    "\t# walk through all files in the folder\n",
    "\tfor filename in listdir(directory):\n",
    "\t\t# skip files that do not have the right extension\n",
    "\t\tif not filename.endswith(\".txt\"):\n",
    "\t\t\tcontinue\n",
    "\t\t# create the full path of the file to open\n",
    "\t\tpath = directory + '/' + filename\n",
    "\t\t# add doc to vocab\n",
    "\t\tadd_doc_to_vocab(path, vocab)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46557\n",
      "[('film', 8860), ('one', 5521), ('movie', 5440), ('like', 3553), ('even', 2555), ('good', 2320), ('time', 2283), ('story', 2118), ('films', 2102), ('would', 2042), ('much', 2024), ('also', 1965), ('characters', 1947), ('get', 1921), ('character', 1906), ('two', 1825), ('first', 1768), ('see', 1730), ('well', 1694), ('way', 1668), ('make', 1590), ('really', 1563), ('little', 1491), ('life', 1472), ('plot', 1451), ('people', 1420), ('movies', 1416), ('could', 1395), ('bad', 1374), ('scene', 1373), ('never', 1364), ('best', 1301), ('new', 1277), ('many', 1268), ('doesnt', 1267), ('man', 1266), ('scenes', 1265), ('dont', 1210), ('know', 1207), ('hes', 1150), ('great', 1141), ('another', 1111), ('love', 1089), ('action', 1078), ('go', 1075), ('us', 1065), ('director', 1056), ('something', 1048), ('end', 1047), ('still', 1038)]\n"
     ]
    }
   ],
   "source": [
    "# We can put all of this together and develop a full vocabulary from all documents in the dataset.\n",
    "\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "\t# split into tokens by white space\n",
    "\ttokens = doc.split()\n",
    "\t# remove punctuation from each token\n",
    "\ttable = str.maketrans('', '', punctuation)\n",
    "\ttokens = [w.translate(table) for w in tokens]\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "\ttokens = [word for word in tokens if word.isalpha()]\n",
    "\t# filter out stop words\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\ttokens = [w for w in tokens if not w in stop_words]\n",
    "\t# filter out short tokens\n",
    "\ttokens = [word for word in tokens if len(word) > 1]\n",
    "\treturn tokens\n",
    "\n",
    "# load doc and add to vocab\n",
    "def add_doc_to_vocab(filename, vocab):\n",
    "\t# load doc\n",
    "\tdoc = load_doc(filename)\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(doc)\n",
    "\t# update counts\n",
    "\tvocab.update(tokens)\n",
    "\n",
    "# load all docs in a directory\n",
    "def process_docs(directory, vocab):\n",
    "\t# walk through all files in the folder\n",
    "\tfor filename in listdir(directory):\n",
    "\t\t# skip files that do not have the right extension\n",
    "\t\tif not filename.endswith(\".txt\"):\n",
    "\t\t\tcontinue\n",
    "\t\t# create the full path of the file to open\n",
    "\t\tpath = directory + '/' + filename\n",
    "\t\t# add doc to vocab\n",
    "\t\tadd_doc_to_vocab(path, vocab)\n",
    "\n",
    "# define vocab\n",
    "vocab = Counter()\n",
    "# add all docs to vocab\n",
    "process_docs('/Users/hasanuzz/Desktop/review_data/txt_sentoken/neg', vocab)\n",
    "process_docs('/Users/hasanuzz/Desktop/review_data/txt_sentoken/pos', vocab)\n",
    "# print the size of the vocab\n",
    "print(len(vocab))\n",
    "# print the top words in the vocab\n",
    "print(vocab.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14803\n"
     ]
    }
   ],
   "source": [
    "# Least common words, those that only appear once across all reviews, are not predictive. Perhaps some of the most \n",
    "# common words are not useful too.\n",
    "\n",
    "# keep tokens with > 5 occurrence\n",
    "min_occurane = 5\n",
    "tokens = [k for k,c in vocab.items() if c >= min_occurane]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then save the chosen vocabulary of words to a new file.\n",
    "def save_list(lines, filename):\n",
    "\tdata = '\\n'.join(lines)\n",
    "\tfile = open(filename, 'w')\n",
    "\tfile.write(data)\n",
    "\tfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46557\n",
      "[('film', 8860), ('one', 5521), ('movie', 5440), ('like', 3553), ('even', 2555), ('good', 2320), ('time', 2283), ('story', 2118), ('films', 2102), ('would', 2042), ('much', 2024), ('also', 1965), ('characters', 1947), ('get', 1921), ('character', 1906), ('two', 1825), ('first', 1768), ('see', 1730), ('well', 1694), ('way', 1668), ('make', 1590), ('really', 1563), ('little', 1491), ('life', 1472), ('plot', 1451), ('people', 1420), ('movies', 1416), ('could', 1395), ('bad', 1374), ('scene', 1373), ('never', 1364), ('best', 1301), ('new', 1277), ('many', 1268), ('doesnt', 1267), ('man', 1266), ('scenes', 1265), ('dont', 1210), ('know', 1207), ('hes', 1150), ('great', 1141), ('another', 1111), ('love', 1089), ('action', 1078), ('go', 1075), ('us', 1065), ('director', 1056), ('something', 1048), ('end', 1047), ('still', 1038)]\n",
      "14803\n"
     ]
    }
   ],
   "source": [
    "# The complete example for defining and saving the vocabulary is listed below.\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "\t# split into tokens by white space\n",
    "\ttokens = doc.split()\n",
    "\t# remove punctuation from each token\n",
    "\ttable = str.maketrans('', '', punctuation)\n",
    "\ttokens = [w.translate(table) for w in tokens]\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "\ttokens = [word for word in tokens if word.isalpha()]\n",
    "\t# filter out stop words\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\ttokens = [w for w in tokens if not w in stop_words]\n",
    "\t# filter out short tokens\n",
    "\ttokens = [word for word in tokens if len(word) > 1]\n",
    "\treturn tokens\n",
    "\n",
    "# load doc and add to vocab\n",
    "def add_doc_to_vocab(filename, vocab):\n",
    "\t# load doc\n",
    "\tdoc = load_doc(filename)\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(doc)\n",
    "\t# update counts\n",
    "\tvocab.update(tokens)\n",
    "\n",
    "# load all docs in a directory\n",
    "def process_docs(directory, vocab):\n",
    "\t# walk through all files in the folder\n",
    "\tfor filename in listdir(directory):\n",
    "\t\t# skip files that do not have the right extension\n",
    "\t\tif not filename.endswith(\".txt\"):\n",
    "\t\t\tcontinue\n",
    "\t\t# create the full path of the file to open\n",
    "\t\tpath = directory + '/' + filename\n",
    "\t\t# add doc to vocab\n",
    "\t\tadd_doc_to_vocab(path, vocab)\n",
    "\n",
    "# save list to file\n",
    "def save_list(lines, filename):\n",
    "\tdata = '\\n'.join(lines)\n",
    "\tfile = open(filename, 'w')\n",
    "\tfile.write(data)\n",
    "\tfile.close()\n",
    "\n",
    "# define vocab\n",
    "vocab = Counter()\n",
    "# add all docs to vocab\n",
    "process_docs('/Users/hasanuzz/Desktop/review_data/txt_sentoken/neg', vocab)\n",
    "process_docs('/Users/hasanuzz/Desktop/review_data/txt_sentoken/pos', vocab)\n",
    "# print the size of the vocab\n",
    "print(len(vocab))\n",
    "# print the top words in the vocab\n",
    "print(vocab.most_common(50))\n",
    "# keep tokens with > 5 occurrence\n",
    "min_occurane = 5\n",
    "tokens = [k for k,c in vocab.items() if c >= min_occurane]\n",
    "print(len(tokens))\n",
    "# save tokens to a vocabulary file\n",
    "save_list(tokens, '/Users/hasanuzz/Desktop/review_data/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 (Final Step): Save Prepared Data\n",
    "\n",
    "# We can use the data cleaning and chosen vocabulary to prepare each movie review and save the prepared versions of the \n",
    "# reviews ready for modeling. This is a good practice as it decouples the data preparation from modeling, allowing you \n",
    "# to focus on modeling and circle back to data prep if you have new ideas.\n",
    "\n",
    "# We can start off by loading the vocabulary from ‘vocab.txt‘.\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# load vocabulary\n",
    "vocab_filename = '/Users/hasanuzz/Desktop/review_data/vocab.txt'\n",
    "vocab = load_doc(vocab_filename)\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we can clean the reviews, use the loaded vocab to filter out unwanted tokens, and save the clean reviews in a \n",
    "# new file. One approach could be to save all the positive reviews in one file and all the negative reviews in another \n",
    "# file, with the filtered tokens separated by white space for each review on separate lines.\n",
    "\n",
    "# First, we can define a function to process a document, clean it, filter it, and return it as a single line that could \n",
    "# be saved in a file. Below defines the doc_to_line() function to do just that, taking a filename and vocabulary\n",
    "# (as a set) as arguments. It calls the previously defined load_doc() function to load the document and clean_doc() \n",
    "# to tokenize the document.\n",
    "\n",
    "# load doc, clean and return line of tokens\n",
    "def doc_to_line(filename, vocab):\n",
    "\t# load the doc\n",
    "\tdoc = load_doc(filename)\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(doc)\n",
    "\t# filter by vocab\n",
    "\ttokens = [w for w in tokens if w in vocab]\n",
    "\treturn ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we can define a new version of process_docs() to step through all reviews in a folder and convert them to \n",
    "# lines by calling doc_to_line() for each document. A list of lines is then returned.\n",
    "\n",
    "# load all docs in a directory\n",
    "def process_docs(directory, vocab):\n",
    "\tlines = list()\n",
    "\t# walk through all files in the folder\n",
    "\tfor filename in listdir(directory):\n",
    "\t\t# skip files that do not have the right extension\n",
    "\t\tif not filename.endswith(\".txt\"):\n",
    "\t\t\tcontinue\n",
    "\t\t# create the full path of the file to open\n",
    "\t\tpath = directory + '/' + filename\n",
    "\t\t# load and clean the doc\n",
    "\t\tline = doc_to_line(path, vocab)\n",
    "\t\t# add to list\n",
    "\t\tlines.append(line)\n",
    "\treturn lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then call process_docs() for both the directories of positive and negative reviews, then call save_list() \n",
    "# from the previous section to save each list of processed reviews to a file.\n",
    "\n",
    "# The complete code \n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "\t# split into tokens by white space\n",
    "\ttokens = doc.split()\n",
    "\t# remove punctuation from each token\n",
    "\ttable = str.maketrans('', '', punctuation)\n",
    "\ttokens = [w.translate(table) for w in tokens]\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "\ttokens = [word for word in tokens if word.isalpha()]\n",
    "\t# filter out stop words\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\ttokens = [w for w in tokens if not w in stop_words]\n",
    "\t# filter out short tokens\n",
    "\ttokens = [word for word in tokens if len(word) > 1]\n",
    "\treturn tokens\n",
    "\n",
    "# save list to file\n",
    "def save_list(lines, filename):\n",
    "\tdata = '\\n'.join(lines)\n",
    "\tfile = open(filename, 'w')\n",
    "\tfile.write(data)\n",
    "\tfile.close()\n",
    "\n",
    "# load doc, clean and return line of tokens\n",
    "def doc_to_line(filename, vocab):\n",
    "\t# load the doc\n",
    "\tdoc = load_doc(filename)\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(doc)\n",
    "\t# filter by vocab\n",
    "\ttokens = [w for w in tokens if w in vocab]\n",
    "\treturn ' '.join(tokens)\n",
    "\n",
    "# load all docs in a directory\n",
    "def process_docs(directory, vocab):\n",
    "\tlines = list()\n",
    "\t# walk through all files in the folder\n",
    "\tfor filename in listdir(directory):\n",
    "\t\t# skip files that do not have the right extension\n",
    "\t\tif not filename.endswith(\".txt\"):\n",
    "\t\t\tcontinue\n",
    "\t\t# create the full path of the file to open\n",
    "\t\tpath = directory + '/' + filename\n",
    "\t\t# load and clean the doc\n",
    "\t\tline = doc_to_line(path, vocab)\n",
    "\t\t# add to list\n",
    "\t\tlines.append(line)\n",
    "\treturn lines\n",
    "\n",
    "# load vocabulary\n",
    "vocab_filename = '/Users/hasanuzz/Desktop/review_data/vocab.txt'\n",
    "vocab = load_doc(vocab_filename)\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)\n",
    "# prepare negative reviews\n",
    "negative_lines = process_docs('/Users/hasanuzz/Desktop/review_data/txt_sentoken/neg', vocab)\n",
    "save_list(negative_lines, '/Users/hasanuzz/Desktop/review_data/negative.txt')\n",
    "# prepare positive reviews\n",
    "positive_lines = process_docs('/Users/hasanuzz/Desktop/review_data/txt_sentoken/pos', vocab)\n",
    "save_list(positive_lines, '/Users/hasanuzz/Desktop/review_data/positive.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
